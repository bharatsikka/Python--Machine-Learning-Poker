{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "wine = load_wine()\n",
    "x_train,x_test,y_train,y_test = train_test_split(wine.data,wine.target, random_state=1204)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(C=100)\n",
    "svm.fit(x_train,y_train)\n",
    "print(svm.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44942528735632187"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(svm,wine.data,wine.target)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[0.001,0.01,0.1,1,10,100],'gamma':[0.001,0.01,0.1,1,10,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline  import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline(MinMaxScaler(), SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "wine = load_wine()\n",
    "x_train,x_test,y_train,y_test = train_test_split(wine.data,wine.target,random_state=1204)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "pipe1.fit(x_train,y_train)\n",
    "print(pipe1.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "pipe2 = make_pipeline(StandardScaler(), SVC())\n",
    "pipe2.fit(x_train,y_train)\n",
    "print(pipe2.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "pipe3 = make_pipeline(RobustScaler(), SVC())\n",
    "pipe3.fit(x_train,y_train)\n",
    "print(pipe3.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4222222222222222\n"
     ]
    }
   ],
   "source": [
    "pipe4 = make_pipeline(Normalizer(), SVC())\n",
    "pipe4.fit(x_train,y_train)\n",
    "print(pipe4.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cv score 0.9849624060150376\n",
      "best score 1.0\n",
      "best parameters {'svc__C': 1, 'svc__gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C':[0.01,0.1,1,10,100],'svc__gamma':[0.001,0.01,0.1,1,10,100]}\n",
    "grid1 = GridSearchCV(pipe1,param_grid=param_grid,cv=5)\n",
    "grid1.fit(x_train,y_train)\n",
    "print(\"best cv score\", grid1.best_score_)\n",
    "print(\"best score\", grid1.score(x_test,y_test))\n",
    "print(\"best parameters\", grid1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Labels are: [1 2 0 1 2 1 2 0 1 2 2 0 2 2 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 2 2\n",
      " 2 0 0 0 2 2 2 2]\n",
      "Accuracy of test set:  100.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predict1 = grid1.predict(x_test)\n",
    "print(\"Test Labels are:\", predict1)\n",
    "print(\"Accuracy of test set: \", np.mean(predict1==y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cv score 0.9849624060150376\n",
      "best score 1.0\n",
      "best parameters {'svc__C': 1, 'svc__gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C':[0.01,0.1,1,10,100],'svc__gamma':[0.001,0.01,0.1,1,10,100]}\n",
    "grid2 = GridSearchCV(pipe2,param_grid=param_grid,cv=5)\n",
    "grid2.fit(x_train,y_train)\n",
    "print(\"best cv score\", grid2.best_score_)\n",
    "print(\"best score\", grid2.score(x_test,y_test))\n",
    "print(\"best parameters\", grid2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Labels are: [1 2 0 1 2 1 2 0 1 2 2 0 2 2 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 2 2\n",
      " 2 0 0 0 2 2 2 2]\n",
      "Accuracy of test set:  100.0\n"
     ]
    }
   ],
   "source": [
    "predict2 = grid2.predict(x_test)\n",
    "print(\"Test Labels are:\", predict2)\n",
    "print(\"Accuracy of test set: \", np.mean(predict2==y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cv score 0.9548872180451128\n",
      "best score 0.9777777777777777\n",
      "best parameters {'svc__C': 1, 'svc__gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C':[0.01,0.1,1,10,100],'svc__gamma':[0.001,0.01,0.1,1,10,100]}\n",
    "grid3 = GridSearchCV(pipe3,param_grid=param_grid,cv=5)\n",
    "grid3.fit(x_train,y_train)\n",
    "print(\"best cv score\", grid3.best_score_)\n",
    "print(\"best score\", grid3.score(x_test,y_test))\n",
    "print(\"best parameters\", grid3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Labels are: [1 2 0 1 2 1 2 0 1 2 2 0 2 2 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 2 2\n",
      " 2 0 0 0 2 2 2 2]\n",
      "Accuracy of test set:  97.77777777777777\n"
     ]
    }
   ],
   "source": [
    "predict3 = grid3.predict(x_test)\n",
    "print(\"Test Labels are:\", predict3)\n",
    "print(\"Accuracy of test set: \", np.mean(predict3==y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cv score 0.9172932330827067\n",
      "best score 0.9777777777777777\n",
      "best parameters {'svc__C': 100, 'svc__gamma': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C':[0.01,0.1,1,10,100],'svc__gamma':[0.001,0.01,0.1,1,10,100]}\n",
    "grid4 = GridSearchCV(pipe4,param_grid=param_grid,cv=5)\n",
    "grid4.fit(x_train,y_train)\n",
    "print(\"best cv score\", grid4.best_score_)\n",
    "print(\"best score\", grid4.score(x_test,y_test))\n",
    "print(\"best parameters\", grid4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Labels are: [1 2 0 1 2 1 2 0 0 2 2 0 2 2 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 2 2\n",
      " 2 0 0 0 2 2 2 2]\n",
      "Accuracy of test set:  97.77777777777777\n"
     ]
    }
   ],
   "source": [
    "predict4 = grid4.predict(x_test)\n",
    "print(\"Test Labels are:\", predict4)\n",
    "print(\"Accuracy of test set: \", np.mean(predict4==y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def dist(x1,x2):\n",
    "    return np.linalg.norm(x1-x2)\n",
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]\n",
    "dist_own = math.inf + np.ones(n_train)\n",
    "dist_other = math.inf + np.ones(n_train)\n",
    "for i in range(n_train-1):\n",
    "    for j in range(i+1,n_train):\n",
    "        current_dist = dist(x_train[i],x_train[j])\n",
    "        if y_train[i] == y_train[j]:\n",
    "            if(current_dist<dist_own[i]):\n",
    "                dist_own[i] = current_dist\n",
    "            if(current_dist<dist_own[j]):\n",
    "                dist_own[j] = current_dist\n",
    "        else:\n",
    "            if(current_dist<dist_other[i]):\n",
    "                dist_other[i] = current_dist\n",
    "            if(current_dist<dist_other[j]):\n",
    "                dist_other[j] = current_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.zeros(n_train+1)\n",
    "p = np.zeros((n_test,3))\n",
    "for j in range(n_test):\n",
    "    for i in range(3):\n",
    "        aug_dist_own = np.append(dist_own,math.inf)\n",
    "        aug_dist_other = np.append(dist_other,math.inf)\n",
    "        for i in range(n_train):\n",
    "            current_dist = dist(x_train[i],x_test[j])\n",
    "            if y_train[i] ==1:\n",
    "                if (current_dist <aug_dist_own[i]):\n",
    "                    aug_dist_own[i] = current_dist\n",
    "                if(current_dist<aug_dist_own[n_train]):\n",
    "                    aug_dist_own[n_train] = current_dist\n",
    "            else:\n",
    "                if(current_dist<aug_dist_other[i]):\n",
    "                    aug_dist_other[i] = current_dist\n",
    "                if(current_dist<aug_dist_other[n_train]):\n",
    "                    aug_dist_other[n_train] = current_dist\n",
    "        for i in range(n_train+1):\n",
    "            if aug_dist_own[i] == 0:\n",
    "                score[i] = math.inf\n",
    "                if(aug_dist_other[i]==0):\n",
    "                    score[i]=0\n",
    "            else:\n",
    "                score[i] = aug_dist_other[i] / aug_dist_own[i]\n",
    "        p[j,1] = np.mean(score<=score[n_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2184931c8d0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "eps = np.zeros(100)\n",
    "err = np.zeros(100)\n",
    "for k in range(100):\n",
    "    eps[k] = k/100\n",
    "    err[k] = 0\n",
    "    for j in range(n_test):\n",
    "        if(p[j,y_test[j]]<=eps[k]):\n",
    "            err[k] = err[k] +1\n",
    "    err[k] = err[k] /n_test\n",
    "plt.plot(eps,err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = np.genfromtxt(\"C:/Users/bhara/OneDrive/Desktop/ML_Assignment3/zip.test\")\n",
    "d2 = np.genfromtxt(\"C:/Users/bhara/OneDrive/Desktop/ML_Assignment3/zip.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = np.concatenate((d2,d1),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipxtrain,zipxtest,zipytrain,zipytest = train_test_split(d3[:,1:],d3[:,0],random_state=1204)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6973, 256)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipxtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6973,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9724731182795698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svmzip = SVC(C=100)\n",
    "svmzip.fit(zipxtrain,zipytrain)\n",
    "print(svmzip.score(zipxtest,zipytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714928653783712"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scorescvzip = cross_val_score(svmzip,d3[:,1:],d3[:,0])\n",
    "np.mean(scorescvzip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline  import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipezip1 = make_pipeline(MinMaxScaler(), SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9539784946236559\n"
     ]
    }
   ],
   "source": [
    "pipezip1.fit(zipxtrain,zipytrain)\n",
    "print(pipezip1.score(zipxtest,zipytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9664516129032258\n"
     ]
    }
   ],
   "source": [
    "pipezip2 = make_pipeline(StandardScaler(), SVC())\n",
    "pipezip2.fit(zipxtrain,zipytrain)\n",
    "print(pipezip2.score(zipxtest,zipytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8627956989247312\n"
     ]
    }
   ],
   "source": [
    "pipezip3 = make_pipeline(RobustScaler(), SVC())\n",
    "pipezip3.fit(zipxtrain,zipytrain)\n",
    "print(pipezip3.score(zipxtest,zipytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6924731182795699\n"
     ]
    }
   ],
   "source": [
    "pipezip4 = make_pipeline(Normalizer(), SVC())\n",
    "pipezip4.fit(zipxtrain,zipytrain)\n",
    "print(pipezip4.score(zipxtest,zipytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cv score 0.9619962713322816\n",
      "best score 0.9634408602150538\n",
      "best parameters {'svc__C': 1, 'svc__gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C':[0.01,0.1,1],'svc__gamma':[0.001,0.01,0.1]}\n",
    "gridzip1 = GridSearchCV(pipezip1,param_grid=param_grid,cv=5)\n",
    "gridzip1.fit(zipxtrain,zipytrain)\n",
    "print(\"best cv score\", gridzip1.best_score_)\n",
    "print(\"best score\", gridzip1.score(zipxtest,zipytest))\n",
    "print(\"best parameters\", gridzip1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Labels are: [5. 7. 3. ... 7. 3. 0.]\n",
      "Accuracy of test set:  96.34408602150538\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictzip1 = gridzip1.predict(zipxtest)\n",
    "print(\"Test Labels are:\", predictzip1)\n",
    "print(\"Accuracy of test set: \", np.mean(predictzip1==zipytest)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cv score 0.9531048329270042\n",
      "best score 0.9591397849462365\n",
      "best parameters {'svc__C': 1, 'svc__gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C':[0.01,0.1,1],'svc__gamma':[0.001,0.01,0.1]}\n",
    "gridzip2 = GridSearchCV(pipezip2,param_grid=param_grid,cv=5)\n",
    "gridzip2.fit(zipxtrain,zipytrain)\n",
    "print(\"best cv score\", gridzip2.best_score_)\n",
    "print(\"best score\", gridzip2.score(zipxtest,zipytest))\n",
    "print(\"best parameters\", gridzip2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Labels are: [5. 7. 3. ... 7. 3. 0.]\n",
      "Accuracy of test set:  95.91397849462365\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictzip2 = gridzip2.predict(zipxtest)\n",
    "print(\"Test Labels are:\", predictzip2)\n",
    "print(\"Accuracy of test set: \", np.mean(predictzip2==zipytest)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cv score 0.8518571633443281\n",
      "best score 0.8855913978494624\n",
      "best parameters {'svc__C': 1, 'svc__gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C':[0.01,0.1,1],'svc__gamma':[0.001,0.01,0.1]}\n",
    "gridzip3 = GridSearchCV(pipezip3,param_grid=param_grid,cv=5)\n",
    "gridzip3.fit(zipxtrain,zipytrain)\n",
    "print(\"best cv score\", gridzip3.best_score_)\n",
    "print(\"best score\", gridzip3.score(zipxtest,zipytest))\n",
    "print(\"best parameters\", gridzip3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Labels are: [5. 7. 3. ... 7. 3. 0.]\n",
      "Accuracy of test set:  88.55913978494624\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictzip3 = gridzip3.predict(zipxtest)\n",
    "print(\"Test Labels are:\", predictzip3)\n",
    "print(\"Accuracy of test set: \", np.mean(predictzip3==zipytest)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cv score 0.9397676753190879\n",
      "best score 0.9432258064516129\n",
      "best parameters {'svc__C': 1, 'svc__gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C':[0.01,0.1,1],'svc__gamma':[0.001,0.01,0.1]}\n",
    "gridzip4 = GridSearchCV(pipezip4,param_grid=param_grid,cv=5)\n",
    "gridzip4.fit(zipxtrain,zipytrain)\n",
    "print(\"best cv score\", gridzip4.best_score_)\n",
    "print(\"best score\", gridzip4.score(zipxtest,zipytest))\n",
    "print(\"best parameters\", gridzip4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Labels are: [5. 7. 3. ... 7. 3. 4.]\n",
      "Accuracy of test set:  94.3225806451613\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictzip4 = gridzip4.predict(zipxtest)\n",
    "print(\"Test Labels are:\", predictzip4)\n",
    "print(\"Accuracy of test set: \", np.mean(predictzip4==zipytest)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For both the cases Normalisation with StandardScaler and MinMaxScaler are the most efficient</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
